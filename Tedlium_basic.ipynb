{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fb18828",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fb18828",
        "outputId": "e262f7a1-66a8-48f4-bed4-e71c0f6d0bfc",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Collecting TorchCRF\n",
            "  Downloading TorchCRF-1.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from TorchCRF) (1.26.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading TorchCRF-1.1.0-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: TorchCRF\n",
            "Successfully installed TorchCRF-1.1.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-24.3.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: datasets[audio] in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets[audio]) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (3.10.10)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.12.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.10.2.post1)\n",
            "Requirement already satisfied: soxr>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.5.0.post1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->datasets[audio]) (1.17.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (0.60.0)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.8.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets[audio]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets[audio]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets[audio]) (2024.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (2.22)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->datasets[audio]) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->datasets[audio]) (4.3.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets[audio]) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->datasets[audio]) (3.5.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets[audio]) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=560d9b8809163926d92b556e2b514e7134a8c73f7d93ad85658d175e614aa39a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "%pip install torch TorchCRF\n",
        "%pip install torch torchaudio\n",
        "%pip install datasets\n",
        "%pip install transformers\n",
        "%pip install --upgrade pip\n",
        "%pip install --upgrade transformers accelerate datasets[audio]\n",
        "%pip install soundfile\n",
        "%pip install evaluate\n",
        "%pip install seqeval\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.12\n",
        "!pip install tensorflow-addons==0.20.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7JMUwxBC542I",
        "outputId": "fb078fec-3acd-4b69-e2f2-69664ca9212f",
        "collapsed": true
      },
      "id": "7JMUwxBC542I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.12\n",
            "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (24.3.25)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.67.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.12.1)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.4.33)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.16.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12) (0.45.0)\n",
            "Requirement already satisfied: jaxlib<=0.4.33,>=0.4.33 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.4.33)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.4.1)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.35-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.34-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.31-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.30-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (1.13.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.2.2)\n",
            "Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading jaxlib-0.4.30-cp310-cp310-manylinux2014_x86_64.whl (79.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, numpy, keras, gast, jaxlib, google-auth-oauthlib, tensorboard, jax, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.16.0\n",
            "    Uninstalling wrapt-1.16.0:\n",
            "      Successfully uninstalled wrapt-1.16.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.33\n",
            "    Uninstalling jaxlib-0.4.33:\n",
            "      Successfully uninstalled jaxlib-0.4.33\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.33\n",
            "    Uninstalling jax-0.4.33:\n",
            "      Successfully uninstalled jax-0.4.33\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.26.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.12.0 which is incompatible.\n",
            "xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 numpy-1.23.5 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "jax",
                  "jaxlib",
                  "keras",
                  "numpy",
                  "tensorflow",
                  "wrapt"
                ]
              },
              "id": "ae512b9db4b94b4e951ed71d501be483"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons==0.20.0\n",
            "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons==0.20.0) (24.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons==0.20.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/591.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.1\n",
            "    Uninstalling typeguard-4.4.1:\n",
            "      Successfully uninstalled typeguard-4.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_text(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return f.read()\n",
        "\n",
        "# Preprocess data with the full entity dictionary\n",
        "def preprocess_data(text, entities):\n",
        "    tokens = text_to_word_sequence(text)\n",
        "    labels = [entities.get(token, 'O') for token in tokens]\n",
        "    return tokens, labels\n",
        "\n",
        "# Define the CRF Layer\n",
        "class CRFLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_tags, **kwargs):\n",
        "        super(CRFLayer, self).__init__(**kwargs)\n",
        "        self.num_tags = num_tags\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.transitions = self.add_weight(\n",
        "            name=\"transitions\",\n",
        "            shape=(self.num_tags, self.num_tags),\n",
        "            initializer=\"glorot_uniform\"\n",
        "        )\n",
        "        super(CRFLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        logits = inputs\n",
        "        log_likelihood = self.compute_log_likelihood(logits, mask)\n",
        "        return log_likelihood, logits\n",
        "\n",
        "    def compute_log_likelihood(self, logits, mask):\n",
        "        batch_size = tf.shape(logits)[0]\n",
        "        seq_len = tf.shape(logits)[1]\n",
        "        trans = self.transitions\n",
        "\n",
        "        log_likelihood = tf.zeros([batch_size])  # Placeholder for actual log-likelihood calculation\n",
        "        return log_likelihood\n",
        "\n",
        "# Custom CRF Loss function\n",
        "def crf_loss(y_true, y_pred):\n",
        "    mask = tf.sequence_mask(lengths=tf.reduce_sum(tf.cast(y_true > 0, tf.int32), axis=-1), maxlen=512)\n",
        "    logits = y_pred[1]  # CRF logits, extracted from the output tuple\n",
        "    log_likelihood = y_pred[0]  # Log-likelihood extracted from CRF layer output\n",
        "    return -tf.reduce_mean(log_likelihood)\n",
        "\n",
        "# Load transcription text and preprocess data\n",
        "def load_and_process_data(file_path, entities_example):\n",
        "    text = load_text(file_path)\n",
        "    tokens, labels = preprocess_data(text, entities_example)\n",
        "\n",
        "    # Encode tokens and labels\n",
        "    word_encoder = LabelEncoder()\n",
        "    word_encoder.fit(tokens)\n",
        "    encoded_tokens = word_encoder.transform(tokens)\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(labels)\n",
        "    encoded_labels = label_encoder.transform(labels)\n",
        "\n",
        "    # Pad sequences for model input\n",
        "    max_len = 1028\n",
        "    X = tf.keras.preprocessing.sequence.pad_sequences([encoded_tokens], maxlen=max_len, padding='post')\n",
        "    Y = tf.keras.preprocessing.sequence.pad_sequences([encoded_labels], maxlen=max_len, padding='post')\n",
        "\n",
        "    return X, Y, tokens, label_encoder\n",
        "\n",
        "# Define your entities dictionary for NER classification with IOB format\n",
        "entities_example = {\n",
        "    'discovery': 'B-EVENT',\n",
        "    'Italian': 'B-LOCATION',\n",
        "    'Wired': 'B-ORG',\n",
        "    'Aimee': 'B-PERSON',\n",
        "    'Mullins': 'I-PERSON',\n",
        "}\n",
        "\n",
        "label_list = [\n",
        "    'O',\n",
        "    'B-PERSON',\n",
        "    'I-PERSON',\n",
        "    'B-ORG',\n",
        "    'I-ORG',\n",
        "    'B-LOCATION',\n",
        "    'I-LOCATION',\n",
        "    'B-EVENT',\n",
        "    'I-EVENT',\n",
        "]\n",
        "\n",
        "# Load and process data for training and testing\n",
        "X_train, Y_train, train_tokens, label_encoder = load_and_process_data(\"transcription_train.txt\", entities_example)\n",
        "X_test, Y_test, test_tokens, _ = load_and_process_data(\"transcription_test_AimeeMullins_1249s.txt\", entities_example)\n",
        "\n",
        "# Define the model architecture\n",
        "input_layer = layers.Input(shape=(1028,))\n",
        "embedding_layer = layers.Embedding(input_dim=10000, output_dim=512, mask_zero=True)(input_layer)\n",
        "bi_lstm_layer = layers.Bidirectional(layers.LSTM(512, return_sequences=True))(embedding_layer)\n",
        "dense_layer = layers.TimeDistributed(layers.Dense(len(label_list)))(bi_lstm_layer)\n",
        "crf_layer = CRFLayer(num_tags=len(label_list))(dense_layer)\n",
        "model = models.Model(inputs=input_layer, outputs=crf_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.01), loss=crf_loss)\n",
        "\n",
        "# Check model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, Y_train, batch_size=32, epochs=10, validation_data=(X_test, Y_test))\n",
        "\n",
        "# Test the model\n",
        "test_loss = model.evaluate(X_test, Y_test)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "\n",
        "# Predict using the trained model\n",
        "predictions = model.predict(X_test)  # Model prediction\n",
        "logits = predictions[1]  # Extract logits from the CRF layer output\n",
        "predicted_labels = tf.argmax(logits, axis=-1)  # Get the predicted labels\n",
        "print(predicted_labels)\n",
        "# Reshape predictions to match the input sequence length\n",
        "predicted_labels = predicted_labels.numpy()\n",
        "\n",
        "# Convert predicted labels to a flat array and ensure it's the same shape\n",
        "predicted_labels = predicted_labels.flatten()\n",
        "\n",
        "# Handle unseen labels by checking if they're part of the original label encoder classes\n",
        "unseen_labels = np.setdiff1d(predicted_labels, label_encoder.classes_)\n",
        "\n",
        "if len(unseen_labels) > 0:\n",
        "    print(f\"Warning: Found unseen labels: {unseen_labels}\")\n",
        "    predicted_labels = np.where(\n",
        "        np.isin(predicted_labels, label_encoder.classes_),\n",
        "        predicted_labels,\n",
        "        label_encoder.transform(['O'] * len(predicted_labels))  # Default to 'O' for unseen labels\n",
        "    )\n",
        "\n",
        "# Decode predicted labels back to original labels\n",
        "decoded_predictions = label_encoder.inverse_transform(predicted_labels)\n",
        "\n",
        "# Display tokens and their corresponding predicted NER labels\n",
        "for token, label in zip(test_tokens, decoded_predictions):\n",
        "    print(f\"Token: {token}, Predicted Label: {label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv0xhPRztYp_",
        "outputId": "abeb87e6-315b-411b-d863-88fa60f88877"
      },
      "id": "lv0xhPRztYp_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_21 (InputLayer)       [(None, 1028)]            0         \n",
            "                                                                 \n",
            " embedding_20 (Embedding)    (None, 1028, 512)         5120000   \n",
            "                                                                 \n",
            " bidirectional_20 (Bidirecti  (None, 1028, 1024)       4198400   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_16 (TimeDi  (None, 1028, 9)          9225      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " crf_layer_16 (CRFLayer)     ((None,),                 81        \n",
            "                              (None, 1028, 9))                   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,327,706\n",
            "Trainable params: 9,327,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['crf_layer_16/transitions:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['crf_layer_16/transitions:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['crf_layer_16/transitions:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['crf_layer_16/transitions:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 26s 26s/step - loss: -6.9551e-05 - crf_layer_16_loss: 0.0000e+00 - crf_layer_16_1_loss: -6.9551e-05 - val_loss: -5.0722e-04 - val_crf_layer_16_loss: 0.0000e+00 - val_crf_layer_16_1_loss: -5.0722e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: -2.5546e-04 - crf_layer_16_loss: 0.0000e+00 - crf_layer_16_1_loss: -2.5546e-04 - val_loss: -6.3604e-04 - val_crf_layer_16_loss: 0.0000e+00 - val_crf_layer_16_1_loss: -6.3604e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: -4.4672e-04 - crf_layer_16_loss: 0.0000e+00 - crf_layer_16_1_loss: -4.4672e-04 - val_loss: -7.6509e-04 - val_crf_layer_16_loss: 0.0000e+00 - val_crf_layer_16_1_loss: -7.6509e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 11s 11s/step - loss: -6.4060e-04 - crf_layer_16_loss: 0.0000e+00 - crf_layer_16_1_loss: -6.4060e-04 - val_loss: -8.9434e-04 - val_crf_layer_16_loss: 0.0000e+00 - val_crf_layer_16_1_loss: -8.9434e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: -8.3618e-04 - crf_layer_16_loss: 0.0000e+00 - crf_layer_16_1_loss: -8.3618e-04 - val_loss: -0.0010 - val_crf_layer_16_loss: 0.0000e+00 - val_crf_layer_16_1_loss: -0.0010\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: -0.0010 - crf_layer_16_loss: 0.0000e+00 - crf_layer_16_1_loss: -0.0010 - val_loss: -0.0012 - val_crf_layer_16_loss: 0.0000e+00 - val_crf_layer_16_1_loss: -0.0012\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: -0.0012 - crf_layer_16_loss: 0.0000e+00 - crf_layer_16_1_loss: -0.0012 - val_loss: -0.0013 - val_crf_layer_16_loss: 0.0000e+00 - val_crf_layer_16_1_loss: -0.0013\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: -0.0014 - crf_layer_16_loss: 0.0000e+00 - crf_layer_16_1_loss: -0.0014 - val_loss: -0.0014 - val_crf_layer_16_loss: 0.0000e+00 - val_crf_layer_16_1_loss: -0.0014\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: -0.0016 - crf_layer_16_loss: 0.0000e+00 - crf_layer_16_1_loss: -0.0016 - val_loss: -0.0015 - val_crf_layer_16_loss: 0.0000e+00 - val_crf_layer_16_1_loss: -0.0015\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: -0.0018 - crf_layer_16_loss: 0.0000e+00 - crf_layer_16_1_loss: -0.0018 - val_loss: -0.0017 - val_crf_layer_16_loss: 0.0000e+00 - val_crf_layer_16_1_loss: -0.0017\n",
            "1/1 [==============================] - 1s 1s/step - loss: -0.0017 - crf_layer_16_loss: 0.0000e+00 - crf_layer_16_1_loss: -0.0017\n",
            "Test Loss: [-0.0016739674611017108, 0.0, -0.0016739674611017108]\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "tf.Tensor([[1 1 1 ... 0 0 0]], shape=(1, 1028), dtype=int64)\n",
            "Warning: Found unseen labels: [0 1 2 3 4 5 6 7 8]\n",
            "Token: i, Predicted Label: O\n",
            "Token: am, Predicted Label: O\n",
            "Token: aimee, Predicted Label: O\n",
            "Token: mullins, Predicted Label: O\n",
            "Token: i'd, Predicted Label: O\n",
            "Token: like, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: share, Predicted Label: O\n",
            "Token: with, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: discovery, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: made, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: few, Predicted Label: O\n",
            "Token: months, Predicted Label: O\n",
            "Token: ago, Predicted Label: O\n",
            "Token: while, Predicted Label: O\n",
            "Token: writing, Predicted Label: O\n",
            "Token: an, Predicted Label: O\n",
            "Token: article, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: italian, Predicted Label: O\n",
            "Token: wired, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: always, Predicted Label: O\n",
            "Token: keep, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: bizarre, Predicted Label: O\n",
            "Token: as, Predicted Label: O\n",
            "Token: handy, Predicted Label: O\n",
            "Token: whenever, Predicted Label: O\n",
            "Token: i'm, Predicted Label: O\n",
            "Token: writing, Predicted Label: O\n",
            "Token: anything, Predicted Label: O\n",
            "Token: but, Predicted Label: O\n",
            "Token: i'd, Predicted Label: O\n",
            "Token: already, Predicted Label: O\n",
            "Token: finished, Predicted Label: O\n",
            "Token: editing, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: piece, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: realized, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: had, Predicted Label: O\n",
            "Token: never, Predicted Label: O\n",
            "Token: once, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: life, Predicted Label: O\n",
            "Token: looked, Predicted Label: O\n",
            "Token: up, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: word, Predicted Label: O\n",
            "Token: disabled, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: see, Predicted Label: O\n",
            "Token: what, Predicted Label: O\n",
            "Token: i'd, Predicted Label: O\n",
            "Token: find, Predicted Label: O\n",
            "Token: let, Predicted Label: O\n",
            "Token: me, Predicted Label: O\n",
            "Token: read, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: entry, Predicted Label: O\n",
            "Token: disabled, Predicted Label: O\n",
            "Token: agitive, Predicted Label: O\n",
            "Token: crippled, Predicted Label: O\n",
            "Token: helpless, Predicted Label: O\n",
            "Token: useless, Predicted Label: O\n",
            "Token: wrecked, Predicted Label: O\n",
            "Token: stalled, Predicted Label: O\n",
            "Token: rect, Predicted Label: O\n",
            "Token: stalled, Predicted Label: O\n",
            "Token: maimed, Predicted Label: O\n",
            "Token: wounded, Predicted Label: O\n",
            "Token: mangled, Predicted Label: O\n",
            "Token: lame, Predicted Label: O\n",
            "Token: mutilated, Predicted Label: O\n",
            "Token: run, Predicted Label: O\n",
            "Token: down, Predicted Label: O\n",
            "Token: worn, Predicted Label: O\n",
            "Token: out, Predicted Label: O\n",
            "Token: weakened, Predicted Label: O\n",
            "Token: impotent, Predicted Label: O\n",
            "Token: castrated, Predicted Label: O\n",
            "Token: paralyzed, Predicted Label: O\n",
            "Token: handicapped, Predicted Label: O\n",
            "Token: senile, Predicted Label: O\n",
            "Token: decrepit, Predicted Label: O\n",
            "Token: laid, Predicted Label: O\n",
            "Token: up, Predicted Label: O\n",
            "Token: don, Predicted Label: O\n",
            "Token: up, Predicted Label: O\n",
            "Token: done, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: done, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: cracked, Predicted Label: O\n",
            "Token: up, Predicted Label: O\n",
            "Token: counted, Predicted Label: O\n",
            "Token: out, Predicted Label: O\n",
            "Token: see, Predicted Label: O\n",
            "Token: also, Predicted Label: O\n",
            "Token: hurt, Predicted Label: O\n",
            "Token: useless, Predicted Label: O\n",
            "Token: hurt, Predicted Label: O\n",
            "Token: useless, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: weak, Predicted Label: O\n",
            "Token: antonyms, Predicted Label: O\n",
            "Token: healthy, Predicted Label: O\n",
            "Token: strong, Predicted Label: O\n",
            "Token: capable, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: reading, Predicted Label: O\n",
            "Token: this, Predicted Label: O\n",
            "Token: list, Predicted Label: O\n",
            "Token: out, Predicted Label: O\n",
            "Token: loud, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: friend, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: at, Predicted Label: O\n",
            "Token: first, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: laughing, Predicted Label: O\n",
            "Token: it, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: so, Predicted Label: O\n",
            "Token: ludicrous, Predicted Label: O\n",
            "Token: but, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: just, Predicted Label: O\n",
            "Token: got, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: passed, Predicted Label: O\n",
            "Token: mangled, Predicted Label: O\n",
            "Token: when, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: voice, Predicted Label: O\n",
            "Token: broke, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: had, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: stop, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: collect, Predicted Label: O\n",
            "Token: myself, Predicted Label: O\n",
            "Token: from, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: emotional, Predicted Label: O\n",
            "Token: shock, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: impact, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: assault, Predicted Label: O\n",
            "Token: from, Predicted Label: O\n",
            "Token: these, Predicted Label: O\n",
            "Token: words, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: assault, Predicted Label: O\n",
            "Token: from, Predicted Label: O\n",
            "Token: these, Predicted Label: O\n",
            "Token: words, Predicted Label: O\n",
            "Token: unleashed, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: know, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: course, Predicted Label: O\n",
            "Token: this, Predicted Label: O\n",
            "Token: is, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: raggedy, Predicted Label: O\n",
            "Token: old, Predicted Label: O\n",
            "Token: tsara, Predicted Label: O\n",
            "Token: so, Predicted Label: O\n",
            "Token: i'm, Predicted Label: O\n",
            "Token: thinking, Predicted Label: O\n",
            "Token: this, Predicted Label: O\n",
            "Token: must, Predicted Label: O\n",
            "Token: be, Predicted Label: O\n",
            "Token: an, Predicted Label: O\n",
            "Token: ancient, Predicted Label: O\n",
            "Token: print, Predicted Label: O\n",
            "Token: date, Predicted Label: O\n",
            "Token: right, Predicted Label: O\n",
            "Token: but, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: fact, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: print, Predicted Label: O\n",
            "Token: date, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: early, Predicted Label: O\n",
            "Token: 1980s, Predicted Label: O\n",
            "Token: when, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: would, Predicted Label: O\n",
            "Token: have, Predicted Label: O\n",
            "Token: been, Predicted Label: O\n",
            "Token: starting, Predicted Label: O\n",
            "Token: primary, Predicted Label: O\n",
            "Token: school, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: forming, Predicted Label: O\n",
            "Token: an, Predicted Label: O\n",
            "Token: understanding, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: myself, Predicted Label: O\n",
            "Token: outside, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: family, Predicted Label: O\n",
            "Token: unit, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: as, Predicted Label: O\n",
            "Token: related, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: other, Predicted Label: O\n",
            "Token: kids, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: world, Predicted Label: O\n",
            "Token: around, Predicted Label: O\n",
            "Token: me, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: needless, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: say, Predicted Label: O\n",
            "Token: thank, Predicted Label: O\n",
            "Token: god, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: wasn't, Predicted Label: O\n",
            "Token: using, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: tsara's, Predicted Label: O\n",
            "Token: back, Predicted Label: O\n",
            "Token: then, Predicted Label: O\n",
            "Token: back, Predicted Label: O\n",
            "Token: then, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: mean, Predicted Label: O\n",
            "Token: from, Predicted Label: O\n",
            "Token: this, Predicted Label: O\n",
            "Token: entry, Predicted Label: O\n",
            "Token: it, Predicted Label: O\n",
            "Token: would, Predicted Label: O\n",
            "Token: seem, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: born, Predicted Label: O\n",
            "Token: into, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: world, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: perceived, Predicted Label: O\n",
            "Token: someone, Predicted Label: O\n",
            "Token: like, Predicted Label: O\n",
            "Token: me, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: have, Predicted Label: O\n",
            "Token: nothing, Predicted Label: O\n",
            "Token: positive, Predicted Label: O\n",
            "Token: whatsoever, Predicted Label: O\n",
            "Token: going, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: them, Predicted Label: O\n",
            "Token: when, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: fact, Predicted Label: O\n",
            "Token: today, Predicted Label: O\n",
            "Token: i'm, Predicted Label: O\n",
            "Token: celebrated, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: opportunities, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: adventures, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: life, Predicted Label: O\n",
            "Token: have, Predicted Label: O\n",
            "Token: procured, Predicted Label: O\n",
            "Token: so, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: immediately, Predicted Label: O\n",
            "Token: went, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: look, Predicted Label: O\n",
            "Token: up, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: 2009, Predicted Label: O\n",
            "Token: online, Predicted Label: O\n",
            "Token: edition, Predicted Label: O\n",
            "Token: expecting, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: find, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: revision, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: expecting, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: find, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: revision, Predicted Label: O\n",
            "Token: worth, Predicted Label: O\n",
            "Token: noting, Predicted Label: O\n",
            "Token: here's, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: updated, Predicted Label: O\n",
            "Token: version, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: this, Predicted Label: O\n",
            "Token: entry, Predicted Label: O\n",
            "Token: unfortunately, Predicted Label: O\n",
            "Token: it's, Predicted Label: O\n",
            "Token: not, Predicted Label: O\n",
            "Token: much, Predicted Label: O\n",
            "Token: better, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: find, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: last, Predicted Label: O\n",
            "Token: two, Predicted Label: O\n",
            "Token: words, Predicted Label: O\n",
            "Token: under, Predicted Label: O\n",
            "Token: near, Predicted Label: O\n",
            "Token: antonyms, Predicted Label: O\n",
            "Token: particularly, Predicted Label: O\n",
            "Token: unsettling, Predicted Label: O\n",
            "Token: whole, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: wholesome, Predicted Label: O\n",
            "Token: so, Predicted Label: O\n",
            "Token: it's, Predicted Label: O\n",
            "Token: not, Predicted Label: O\n",
            "Token: just, Predicted Label: O\n",
            "Token: about, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: words, Predicted Label: O\n",
            "Token: it's, Predicted Label: O\n",
            "Token: what, Predicted Label: O\n",
            "Token: we, Predicted Label: O\n",
            "Token: believe, Predicted Label: O\n",
            "Token: about, Predicted Label: O\n",
            "Token: people, Predicted Label: O\n",
            "Token: when, Predicted Label: O\n",
            "Token: we, Predicted Label: O\n",
            "Token: name, Predicted Label: O\n",
            "Token: them, Predicted Label: O\n",
            "Token: with, Predicted Label: O\n",
            "Token: these, Predicted Label: O\n",
            "Token: words, Predicted Label: O\n",
            "Token: about, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: values, Predicted Label: O\n",
            "Token: behind, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: words, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: how, Predicted Label: O\n",
            "Token: we, Predicted Label: O\n",
            "Token: construct, Predicted Label: O\n",
            "Token: those, Predicted Label: O\n",
            "Token: values, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: struck, Predicted Label: O\n",
            "Token: those, Predicted Label: O\n",
            "Token: values, Predicted Label: O\n",
            "Token: our, Predicted Label: O\n",
            "Token: language, Predicted Label: O\n",
            "Token: affects, Predicted Label: O\n",
            "Token: our, Predicted Label: O\n",
            "Token: thinking, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: how, Predicted Label: O\n",
            "Token: we, Predicted Label: O\n",
            "Token: view, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: world, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: how, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: view, Predicted Label: O\n",
            "Token: other, Predicted Label: O\n",
            "Token: people, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: fact, Predicted Label: O\n",
            "Token: many, Predicted Label: O\n",
            "Token: ancient, Predicted Label: O\n",
            "Token: societies, Predicted Label: O\n",
            "Token: including, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: greeks, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: romans, Predicted Label: O\n",
            "Token: believed, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: utter, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: curse, Predicted Label: O\n",
            "Token: verbally, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: so, Predicted Label: O\n",
            "Token: powerful, Predicted Label: O\n",
            "Token: because, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: say, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: thing, Predicted Label: O\n",
            "Token: out, Predicted Label: O\n",
            "Token: loud, Predicted Label: O\n",
            "Token: brought, Predicted Label: O\n",
            "Token: it, Predicted Label: O\n",
            "Token: into, Predicted Label: O\n",
            "Token: existence, Predicted Label: O\n",
            "Token: so, Predicted Label: O\n",
            "Token: what, Predicted Label: O\n",
            "Token: reality, Predicted Label: O\n",
            "Token: do, Predicted Label: O\n",
            "Token: we, Predicted Label: O\n",
            "Token: want, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: call, Predicted Label: O\n",
            "Token: into, Predicted Label: O\n",
            "Token: existence, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: person, Predicted Label: O\n",
            "Token: who, Predicted Label: O\n",
            "Token: is, Predicted Label: O\n",
            "Token: limited, Predicted Label: O\n",
            "Token: or, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: person, Predicted Label: O\n",
            "Token: or, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: person, Predicted Label: O\n",
            "Token: who's, Predicted Label: O\n",
            "Token: empowered, Predicted Label: O\n",
            "Token: by, Predicted Label: O\n",
            "Token: casually, Predicted Label: O\n",
            "Token: doing, Predicted Label: O\n",
            "Token: something, Predicted Label: O\n",
            "Token: as, Predicted Label: O\n",
            "Token: simple, Predicted Label: O\n",
            "Token: as, Predicted Label: O\n",
            "Token: naming, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: person, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: child, Predicted Label: O\n",
            "Token: we, Predicted Label: O\n",
            "Token: might, Predicted Label: O\n",
            "Token: be, Predicted Label: O\n",
            "Token: putting, Predicted Label: O\n",
            "Token: lids, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: casting, Predicted Label: O\n",
            "Token: shadows, Predicted Label: O\n",
            "Token: on, Predicted Label: O\n",
            "Token: their, Predicted Label: O\n",
            "Token: power, Predicted Label: O\n",
            "Token: wouldn't, Predicted Label: O\n",
            "Token: we, Predicted Label: O\n",
            "Token: want, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: open, Predicted Label: O\n",
            "Token: doors, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: them, Predicted Label: O\n",
            "Token: instead, Predicted Label: O\n",
            "Token: once, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: person, Predicted Label: O\n",
            "Token: who, Predicted Label: O\n",
            "Token: opened, Predicted Label: O\n",
            "Token: doors, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: me, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: childhood, Predicted Label: O\n",
            "Token: doctor, Predicted Label: O\n",
            "Token: at, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: dupont, Predicted Label: O\n",
            "Token: institute, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: wilmington, Predicted Label: O\n",
            "Token: delaware, Predicted Label: O\n",
            "Token: his, Predicted Label: O\n",
            "Token: name, Predicted Label: O\n",
            "Token: is, Predicted Label: O\n",
            "Token: dr, Predicted Label: O\n",
            "Token: where, Predicted Label: O\n",
            "Token: his, Predicted Label: O\n",
            "Token: name, Predicted Label: O\n",
            "Token: is, Predicted Label: O\n",
            "Token: dr, Predicted Label: O\n",
            "Token: pete, Predicted Label: O\n",
            "Token: zotillo, Predicted Label: O\n",
            "Token: i'm, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: italian, Predicted Label: O\n",
            "Token: american, Predicted Label: O\n",
            "Token: whose, Predicted Label: O\n",
            "Token: name, Predicted Label: O\n",
            "Token: apparently, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: too, Predicted Label: O\n",
            "Token: difficult, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: most, Predicted Label: O\n",
            "Token: americans, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: pronounce, Predicted Label: O\n",
            "Token: so, Predicted Label: O\n",
            "Token: he, Predicted Label: O\n",
            "Token: went, Predicted Label: O\n",
            "Token: by, Predicted Label: O\n",
            "Token: dr, Predicted Label: O\n",
            "Token: p, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: dr, Predicted Label: O\n",
            "Token: p, Predicted Label: O\n",
            "Token: always, Predicted Label: O\n",
            "Token: wore, Predicted Label: O\n",
            "Token: really, Predicted Label: O\n",
            "Token: colorful, Predicted Label: O\n",
            "Token: bow, Predicted Label: O\n",
            "Token: ties, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: had, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: very, Predicted Label: O\n",
            "Token: perfect, Predicted Label: O\n",
            "Token: disposition, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: work, Predicted Label: O\n",
            "Token: with, Predicted Label: O\n",
            "Token: children, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: loved, Predicted Label: O\n",
            "Token: almost, Predicted Label: O\n",
            "Token: everything, Predicted Label: O\n",
            "Token: about, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: time, Predicted Label: O\n",
            "Token: spent, Predicted Label: O\n",
            "Token: at, Predicted Label: O\n",
            "Token: this, Predicted Label: O\n",
            "Token: hospital, Predicted Label: O\n",
            "Token: which, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: exception, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: physical, Predicted Label: O\n",
            "Token: therapy, Predicted Label: O\n",
            "Token: sessions, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: had, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: do, Predicted Label: O\n",
            "Token: sessions, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: had, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: do, Predicted Label: O\n",
            "Token: what, Predicted Label: O\n",
            "Token: seemed, Predicted Label: O\n",
            "Token: like, Predicted Label: O\n",
            "Token: innumerable, Predicted Label: O\n",
            "Token: repetitions, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: exercises, Predicted Label: O\n",
            "Token: with, Predicted Label: O\n",
            "Token: these, Predicted Label: O\n",
            "Token: thick, Predicted Label: O\n",
            "Token: elastic, Predicted Label: O\n",
            "Token: bands, Predicted Label: O\n",
            "Token: different, Predicted Label: O\n",
            "Token: colors, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: know, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: help, Predicted Label: O\n",
            "Token: build, Predicted Label: O\n",
            "Token: up, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: leg, Predicted Label: O\n",
            "Token: muscles, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: hated, Predicted Label: O\n",
            "Token: these, Predicted Label: O\n",
            "Token: bands, Predicted Label: O\n",
            "Token: more, Predicted Label: O\n",
            "Token: than, Predicted Label: O\n",
            "Token: anything, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: hated, Predicted Label: O\n",
            "Token: them, Predicted Label: O\n",
            "Token: had, Predicted Label: O\n",
            "Token: names, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: them, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: hate, Predicted Label: O\n",
            "Token: them, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: know, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: already, Predicted Label: O\n",
            "Token: bargaining, Predicted Label: O\n",
            "Token: as, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: five, Predicted Label: O\n",
            "Token: year, Predicted Label: O\n",
            "Token: old, Predicted Label: O\n",
            "Token: child, Predicted Label: O\n",
            "Token: with, Predicted Label: O\n",
            "Token: dr, Predicted Label: O\n",
            "Token: p, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: try, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: get, Predicted Label: O\n",
            "Token: out, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: doing, Predicted Label: O\n",
            "Token: these, Predicted Label: O\n",
            "Token: exercises, Predicted Label: O\n",
            "Token: unsuccessfully, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: course, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: one, Predicted Label: O\n",
            "Token: day, Predicted Label: O\n",
            "Token: he, Predicted Label: O\n",
            "Token: came, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: he, Predicted Label: O\n",
            "Token: came, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: session, Predicted Label: O\n",
            "Token: exhaustive, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: unforgiving, Predicted Label: O\n",
            "Token: these, Predicted Label: O\n",
            "Token: sessions, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: he, Predicted Label: O\n",
            "Token: said, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: me, Predicted Label: O\n",
            "Token: wow, Predicted Label: O\n",
            "Token: amy, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: are, Predicted Label: O\n",
            "Token: such, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: strong, Predicted Label: O\n",
            "Token: powerful, Predicted Label: O\n",
            "Token: little, Predicted Label: O\n",
            "Token: girl, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: think, Predicted Label: O\n",
            "Token: you're, Predicted Label: O\n",
            "Token: going, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: break, Predicted Label: O\n",
            "Token: one, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: those, Predicted Label: O\n",
            "Token: bands, Predicted Label: O\n",
            "Token: when, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: do, Predicted Label: O\n",
            "Token: break, Predicted Label: O\n",
            "Token: it, Predicted Label: O\n",
            "Token: i'm, Predicted Label: O\n",
            "Token: going, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: give, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: 100, Predicted Label: O\n",
            "Token: bucks, Predicted Label: O\n",
            "Token: now, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: course, Predicted Label: O\n",
            "Token: this, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: simple, Predicted Label: O\n",
            "Token: ploy, Predicted Label: O\n",
            "Token: on, Predicted Label: O\n",
            "Token: dr, Predicted Label: O\n",
            "Token: p's, Predicted Label: O\n",
            "Token: part, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: get, Predicted Label: O\n",
            "Token: me, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: do, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: exercises, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: didn't, Predicted Label: O\n",
            "Token: want, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: do, Predicted Label: O\n",
            "Token: before, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: prospect, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: being, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: richest, Predicted Label: O\n",
            "Token: five, Predicted Label: O\n",
            "Token: year, Predicted Label: O\n",
            "Token: old, Predicted Label: O\n",
            "Token: before, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: prospect, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: being, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: richest, Predicted Label: O\n",
            "Token: fighter, Predicted Label: O\n",
            "Token: old, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: second, Predicted Label: O\n",
            "Token: floor, Predicted Label: O\n",
            "Token: award, Predicted Label: O\n",
            "Token: but, Predicted Label: O\n",
            "Token: what, Predicted Label: O\n",
            "Token: he, Predicted Label: O\n",
            "Token: effectively, Predicted Label: O\n",
            "Token: did, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: me, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: reshape, Predicted Label: O\n",
            "Token: an, Predicted Label: O\n",
            "Token: awful, Predicted Label: O\n",
            "Token: daily, Predicted Label: O\n",
            "Token: occurrence, Predicted Label: O\n",
            "Token: into, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: new, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: promising, Predicted Label: O\n",
            "Token: experience, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: me, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: i, Predicted Label: O\n",
            "Token: have, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: wonder, Predicted Label: O\n",
            "Token: today, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: what, Predicted Label: O\n",
            "Token: extent, Predicted Label: O\n",
            "Token: his, Predicted Label: O\n",
            "Token: vision, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: his, Predicted Label: O\n",
            "Token: declaration, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: me, Predicted Label: O\n",
            "Token: as, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: strong, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: powerful, Predicted Label: O\n",
            "Token: little, Predicted Label: O\n",
            "Token: girl, Predicted Label: O\n",
            "Token: shaped, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: own, Predicted Label: O\n",
            "Token: view, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: myself, Predicted Label: O\n",
            "Token: as, Predicted Label: O\n",
            "Token: an, Predicted Label: O\n",
            "Token: inherently, Predicted Label: O\n",
            "Token: strong, Predicted Label: O\n",
            "Token: as, Predicted Label: O\n",
            "Token: an, Predicted Label: O\n",
            "Token: inherently, Predicted Label: O\n",
            "Token: strong, Predicted Label: O\n",
            "Token: powerful, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: athletic, Predicted Label: O\n",
            "Token: person, Predicted Label: O\n",
            "Token: well, Predicted Label: O\n",
            "Token: into, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: future, Predicted Label: O\n",
            "Token: this, Predicted Label: O\n",
            "Token: is, Predicted Label: O\n",
            "Token: an, Predicted Label: O\n",
            "Token: example, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: how, Predicted Label: O\n",
            "Token: adults, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: positions, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: power, Predicted Label: O\n",
            "Token: can, Predicted Label: O\n",
            "Token: ignite, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: power, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: child, Predicted Label: O\n",
            "Token: but, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: previous, Predicted Label: O\n",
            "Token: instances, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: those, Predicted Label: O\n",
            "Token: bessara, Predicted Label: O\n",
            "Token: centuries, Predicted Label: O\n",
            "Token: our, Predicted Label: O\n",
            "Token: language, Predicted Label: O\n",
            "Token: isn't, Predicted Label: O\n",
            "Token: allowing, Predicted Label: O\n",
            "Token: us, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: evolve, Predicted Label: O\n",
            "Token: into, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: reality, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: we, Predicted Label: O\n",
            "Token: would, Predicted Label: O\n",
            "Token: all, Predicted Label: O\n",
            "Token: want, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: possibility, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: an, Predicted Label: O\n",
            "Token: individual, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: see, Predicted Label: O\n",
            "Token: themselves, Predicted Label: O\n",
            "Token: as, Predicted Label: O\n",
            "Token: capable, Predicted Label: O\n",
            "Token: is, Predicted Label: O\n",
            "Token: capable, Predicted Label: O\n",
            "Token: our, Predicted Label: O\n",
            "Token: language, Predicted Label: O\n",
            "Token: hasn't, Predicted Label: O\n",
            "Token: caught, Predicted Label: O\n",
            "Token: up, Predicted Label: O\n",
            "Token: with, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: changes, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: our, Predicted Label: O\n",
            "Token: society, Predicted Label: O\n",
            "Token: many, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: which, Predicted Label: O\n",
            "Token: have, Predicted Label: O\n",
            "Token: been, Predicted Label: O\n",
            "Token: brought, Predicted Label: O\n",
            "Token: about, Predicted Label: O\n",
            "Token: by, Predicted Label: O\n",
            "Token: technology, Predicted Label: O\n",
            "Token: certainly, Predicted Label: O\n",
            "Token: from, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: medical, Predicted Label: O\n",
            "Token: standpoint, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: legs, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: know, Predicted Label: O\n",
            "Token: laser, Predicted Label: O\n",
            "Token: surgery, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: vision, Predicted Label: O\n",
            "Token: impairment, Predicted Label: O\n",
            "Token: titanium, Predicted Label: O\n",
            "Token: knees, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: hip, Predicted Label: O\n",
            "Token: replacements, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: aging, Predicted Label: O\n",
            "Token: bodies, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: are, Predicted Label: O\n",
            "Token: allowing, Predicted Label: O\n",
            "Token: people, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: more, Predicted Label: O\n",
            "Token: fully, Predicted Label: O\n",
            "Token: engage, Predicted Label: O\n",
            "Token: with, Predicted Label: O\n",
            "Token: their, Predicted Label: O\n",
            "Token: abilities, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: move, Predicted Label: O\n",
            "Token: beyond, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: limits, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: nature, Predicted Label: O\n",
            "Token: has, Predicted Label: O\n",
            "Token: imposed, Predicted Label: O\n",
            "Token: on, Predicted Label: O\n",
            "Token: them, Predicted Label: O\n",
            "Token: not, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: mention, Predicted Label: O\n",
            "Token: not, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: mention, Predicted Label: O\n",
            "Token: social, Predicted Label: O\n",
            "Token: networking, Predicted Label: O\n",
            "Token: platforms, Predicted Label: O\n",
            "Token: it, Predicted Label: O\n",
            "Token: allows, Predicted Label: O\n",
            "Token: people, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: self, Predicted Label: O\n",
            "Token: identify, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: claim, Predicted Label: O\n",
            "Token: their, Predicted Label: O\n",
            "Token: own, Predicted Label: O\n",
            "Token: descriptions, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: themselves, Predicted Label: O\n",
            "Token: so, Predicted Label: O\n",
            "Token: they, Predicted Label: O\n",
            "Token: can, Predicted Label: O\n",
            "Token: go, Predicted Label: O\n",
            "Token: align, Predicted Label: O\n",
            "Token: with, Predicted Label: O\n",
            "Token: global, Predicted Label: O\n",
            "Token: groups, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: their, Predicted Label: O\n",
            "Token: own, Predicted Label: O\n",
            "Token: choosing, Predicted Label: O\n",
            "Token: so, Predicted Label: O\n",
            "Token: perhaps, Predicted Label: O\n",
            "Token: technology, Predicted Label: O\n",
            "Token: is, Predicted Label: O\n",
            "Token: revealing, Predicted Label: O\n",
            "Token: more, Predicted Label: O\n",
            "Token: clearly, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: us, Predicted Label: O\n",
            "Token: now, Predicted Label: O\n",
            "Token: what, Predicted Label: O\n",
            "Token: has, Predicted Label: O\n",
            "Token: always, Predicted Label: O\n",
            "Token: been, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: truth, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: everyone, Predicted Label: O\n",
            "Token: has, Predicted Label: O\n",
            "Token: something, Predicted Label: O\n",
            "Token: rare, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: powerful, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: offer, Predicted Label: O\n",
            "Token: our, Predicted Label: O\n",
            "Token: society, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: human, Predicted Label: O\n",
            "Token: ability, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: adapt, Predicted Label: O\n",
            "Token: is, Predicted Label: O\n",
            "Token: our, Predicted Label: O\n",
            "Token: greatest, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: adapt, Predicted Label: O\n",
            "Token: is, Predicted Label: O\n",
            "Token: our, Predicted Label: O\n",
            "Token: greatest, Predicted Label: O\n",
            "Token: asset, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: human, Predicted Label: O\n",
            "Token: ability, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: adapt, Predicted Label: O\n",
            "Token: it's, Predicted Label: O\n",
            "Token: an, Predicted Label: O\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/arraysetops.py:608: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask &= (ar1 != a)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/arraysetops.py:612: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow_addons.text.crf import crf_log_likelihood, viterbi_decode\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_text(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return f.read()\n",
        "\n",
        "def preprocess_data(text, entities):\n",
        "    tokens = text.split()  # Simple whitespace tokenization\n",
        "    labels = [entities.get(token, 'O') for token in tokens]\n",
        "    return tokens, labels\n",
        "\n",
        "# Define CRF Layer\n",
        "class CRFLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_tags, **kwargs):\n",
        "        super(CRFLayer, self).__init__(**kwargs)\n",
        "        self.num_tags = num_tags\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.transitions = self.add_weight(\n",
        "            name=\"transitions\",\n",
        "            shape=(self.num_tags, self.num_tags),\n",
        "            initializer=\"glorot_uniform\"\n",
        "        )\n",
        "        super(CRFLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, logits):\n",
        "        return logits\n",
        "\n",
        "    def get_loss(self, logits, labels, sequence_lengths):\n",
        "        sequence_lengths = tf.cast(sequence_lengths, tf.int32)\n",
        "        log_likelihood, _ = crf_log_likelihood(\n",
        "            logits,\n",
        "            labels,\n",
        "            sequence_lengths,\n",
        "            self.transitions\n",
        "        )\n",
        "        return -tf.reduce_mean(log_likelihood)\n",
        "\n",
        "# Decode CRF predictions\n",
        "def crf_decode(logits, sequence_lengths, transitions):\n",
        "    \"\"\"Decodes logits using Viterbi algorithm.\"\"\"\n",
        "    decoded_sequences = []\n",
        "    for logit, seq_len in zip(logits, sequence_lengths):\n",
        "        viterbi_path, _ = viterbi_decode(logit[:seq_len], transitions)\n",
        "        decoded_sequences.append(viterbi_path)\n",
        "    return decoded_sequences\n",
        "\n",
        "# Load and process data\n",
        "def load_and_process_data(file_path, entities_example, max_len=50):\n",
        "    text = load_text(file_path)\n",
        "    tokens, labels = preprocess_data(text, entities_example)\n",
        "\n",
        "    # Encode tokens and labels\n",
        "    word_encoder = LabelEncoder()\n",
        "    word_encoder.fit(tokens)\n",
        "    encoded_tokens = word_encoder.transform(tokens)\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(labels)\n",
        "    encoded_labels = label_encoder.transform(labels)\n",
        "\n",
        "    # Pad sequences for model input\n",
        "    X = tf.keras.preprocessing.sequence.pad_sequences([encoded_tokens], maxlen=max_len, padding='post')\n",
        "    Y = tf.keras.preprocessing.sequence.pad_sequences([encoded_labels], maxlen=max_len, padding='post')\n",
        "\n",
        "    return X, Y, tokens, label_encoder\n",
        "\n",
        "# Define entities dictionary for NER classification\n",
        "entities_example = {\n",
        "    'discovery': 'B-EVENT',\n",
        "    'Italian': 'B-LOCATION',\n",
        "    'Wired': 'B-ORG',\n",
        "    'Aimee': 'B-PERSON',\n",
        "    'Mullins': 'I-PERSON',\n",
        "}\n",
        "\n",
        "label_list = [\n",
        "    'O', 'B-PERSON', 'I-PERSON', 'B-ORG', 'I-ORG', 'B-LOCATION', 'I-LOCATION', 'B-EVENT', 'I-EVENT'\n",
        "]\n",
        "\n",
        "# Load and process data\n",
        "max_len = 1028\n",
        "X_train, Y_train, train_tokens, label_encoder = load_and_process_data(\"transcription_train.txt\", entities_example, max_len)\n",
        "X_test, Y_test, test_tokens, _ = load_and_process_data(\"transcription_test_AimeeMullins_1249s.txt\", entities_example, max_len)\n",
        "\n",
        "# Define model\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(input_dim=10000, output_dim=128, mask_zero=True)(input_layer)\n",
        "bi_lstm_layer = Bidirectional(LSTM(128, return_sequences=True))(embedding_layer)\n",
        "dense_layer = TimeDistributed(Dense(len(label_list)))(bi_lstm_layer)\n",
        "\n",
        "# CRF Layer\n",
        "crf_layer = CRFLayer(num_tags=len(label_list))\n",
        "logits = crf_layer(dense_layer)\n",
        "\n",
        "# Build model\n",
        "model = Model(inputs=input_layer, outputs=logits)\n",
        "\n",
        "# Compile with dummy loss (manual loss handling below)\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss=\"sparse_categorical_crossentropy\")\n",
        "\n",
        "# Compute sequence lengths\n",
        "sequence_lengths = tf.reduce_sum(tf.cast(tf.not_equal(X_train, 0), tf.int32), axis=-1)\n",
        "\n",
        "# Training step with custom CRF loss\n",
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(x, training=True)\n",
        "        loss = crf_layer.get_loss(logits, y, sequence_lengths)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    loss = train_step(X_train, Y_train)\n",
        "    print(f\"Loss: {loss.numpy()}\")\n",
        "\n",
        "# Decoding predictions\n",
        "sequence_lengths_test = tf.reduce_sum(tf.cast(tf.not_equal(X_test, 0), tf.int32), axis=-1).numpy()\n",
        "predictions = model.predict(X_test)\n",
        "decoded_predictions = crf_decode(predictions, sequence_lengths_test, crf_layer.transitions)\n",
        "\n",
        "# Map predictions back to labels\n",
        "decoded_labels = []\n",
        "for pred in decoded_predictions:\n",
        "    decoded_labels.append(label_encoder.inverse_transform(pred))\n",
        "\n",
        "# Display tokens and predicted NER labels\n",
        "for token, label in zip(test_tokens, decoded_labels[0]):\n",
        "    print(f\"Token: {token}, Predicted Label: {label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CExSZqJWWRxj",
        "outputId": "c91b35b5-6a48-40f1-bb9f-6c193b3bf73a"
      },
      "id": "CExSZqJWWRxj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Loss: 359.75457763671875\n",
            "Epoch 2/10\n",
            "Loss: 350.3329772949219\n",
            "Epoch 3/10\n",
            "Loss: 340.4454040527344\n",
            "Epoch 4/10\n",
            "Loss: 328.8652648925781\n",
            "Epoch 5/10\n",
            "Loss: 314.1257019042969\n",
            "Epoch 6/10\n",
            "Loss: 293.92193603515625\n",
            "Epoch 7/10\n",
            "Loss: 264.21484375\n",
            "Epoch 8/10\n",
            "Loss: 216.7753143310547\n",
            "Epoch 9/10\n",
            "Loss: 135.96902465820312\n",
            "Epoch 10/10\n",
            "Loss: 68.84320068359375\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "Token: I, Predicted Label: O\n",
            "Token: am, Predicted Label: O\n",
            "Token: Aimee, Predicted Label: O\n",
            "Token: Mullins., Predicted Label: O\n",
            "Token: I'd, Predicted Label: O\n",
            "Token: like, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: share, Predicted Label: O\n",
            "Token: with, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: discovery, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: made, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: few, Predicted Label: O\n",
            "Token: months, Predicted Label: O\n",
            "Token: ago, Predicted Label: O\n",
            "Token: while, Predicted Label: O\n",
            "Token: writing, Predicted Label: O\n",
            "Token: an, Predicted Label: O\n",
            "Token: article, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: Italian, Predicted Label: O\n",
            "Token: Wired., Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: always, Predicted Label: O\n",
            "Token: keep, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: bizarre, Predicted Label: O\n",
            "Token: as, Predicted Label: O\n",
            "Token: handy, Predicted Label: O\n",
            "Token: whenever, Predicted Label: O\n",
            "Token: I'm, Predicted Label: O\n",
            "Token: writing, Predicted Label: O\n",
            "Token: anything,, Predicted Label: O\n",
            "Token: but, Predicted Label: O\n",
            "Token: I'd, Predicted Label: O\n",
            "Token: already, Predicted Label: O\n",
            "Token: finished, Predicted Label: O\n",
            "Token: editing, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: piece, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: realized, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: had, Predicted Label: O\n",
            "Token: never, Predicted Label: O\n",
            "Token: once, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: life, Predicted Label: O\n",
            "Token: looked, Predicted Label: O\n",
            "Token: up, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: word, Predicted Label: O\n",
            "Token: disabled, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: see, Predicted Label: O\n",
            "Token: what, Predicted Label: O\n",
            "Token: I'd, Predicted Label: O\n",
            "Token: find., Predicted Label: O\n",
            "Token: Let, Predicted Label: O\n",
            "Token: me, Predicted Label: O\n",
            "Token: read, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: entry., Predicted Label: O\n",
            "Token: Disabled,, Predicted Label: O\n",
            "Token: agitive,, Predicted Label: O\n",
            "Token: crippled,, Predicted Label: O\n",
            "Token: helpless,, Predicted Label: O\n",
            "Token: useless,, Predicted Label: O\n",
            "Token: wrecked,, Predicted Label: O\n",
            "Token: stalled,, Predicted Label: O\n",
            "Token: Rect,, Predicted Label: O\n",
            "Token: stalled,, Predicted Label: O\n",
            "Token: maimed,, Predicted Label: O\n",
            "Token: wounded,, Predicted Label: O\n",
            "Token: mangled,, Predicted Label: O\n",
            "Token: lame,, Predicted Label: O\n",
            "Token: mutilated,, Predicted Label: O\n",
            "Token: run, Predicted Label: O\n",
            "Token: down,, Predicted Label: O\n",
            "Token: worn, Predicted Label: O\n",
            "Token: out,, Predicted Label: O\n",
            "Token: weakened,, Predicted Label: O\n",
            "Token: impotent,, Predicted Label: O\n",
            "Token: castrated,, Predicted Label: O\n",
            "Token: paralyzed,, Predicted Label: O\n",
            "Token: handicapped,, Predicted Label: O\n",
            "Token: senile,, Predicted Label: O\n",
            "Token: decrepit,, Predicted Label: O\n",
            "Token: laid, Predicted Label: O\n",
            "Token: up,, Predicted Label: O\n",
            "Token: don, Predicted Label: O\n",
            "Token: up,, Predicted Label: O\n",
            "Token: done, Predicted Label: O\n",
            "Token: for,, Predicted Label: O\n",
            "Token: done, Predicted Label: O\n",
            "Token: in,, Predicted Label: O\n",
            "Token: cracked, Predicted Label: O\n",
            "Token: up,, Predicted Label: O\n",
            "Token: counted, Predicted Label: O\n",
            "Token: out., Predicted Label: O\n",
            "Token: See, Predicted Label: O\n",
            "Token: also, Predicted Label: O\n",
            "Token: hurt,, Predicted Label: O\n",
            "Token: useless,, Predicted Label: O\n",
            "Token: hurt,, Predicted Label: O\n",
            "Token: useless,, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: weak., Predicted Label: O\n",
            "Token: Antonyms,, Predicted Label: O\n",
            "Token: healthy,, Predicted Label: O\n",
            "Token: strong,, Predicted Label: O\n",
            "Token: capable., Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: reading, Predicted Label: O\n",
            "Token: this, Predicted Label: O\n",
            "Token: list, Predicted Label: O\n",
            "Token: out, Predicted Label: O\n",
            "Token: loud, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: friend, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: at, Predicted Label: O\n",
            "Token: first, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: laughing,, Predicted Label: O\n",
            "Token: it, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: so, Predicted Label: O\n",
            "Token: ludicrous,, Predicted Label: O\n",
            "Token: but, Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: just, Predicted Label: O\n",
            "Token: got, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: passed, Predicted Label: O\n",
            "Token: mangled, Predicted Label: O\n",
            "Token: when, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: voice, Predicted Label: O\n",
            "Token: broke, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: had, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: stop, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: collect, Predicted Label: O\n",
            "Token: myself, Predicted Label: O\n",
            "Token: from, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: emotional, Predicted Label: O\n",
            "Token: shock, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: impact, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: assault, Predicted Label: O\n",
            "Token: from, Predicted Label: O\n",
            "Token: these, Predicted Label: O\n",
            "Token: words, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: assault, Predicted Label: O\n",
            "Token: from, Predicted Label: O\n",
            "Token: these, Predicted Label: O\n",
            "Token: words, Predicted Label: O\n",
            "Token: unleashed., Predicted Label: O\n",
            "Token: You, Predicted Label: O\n",
            "Token: know,, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: course,, Predicted Label: O\n",
            "Token: this, Predicted Label: O\n",
            "Token: is, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: raggedy, Predicted Label: O\n",
            "Token: old, Predicted Label: O\n",
            "Token: Tsara,, Predicted Label: O\n",
            "Token: so, Predicted Label: O\n",
            "Token: I'm, Predicted Label: O\n",
            "Token: thinking, Predicted Label: O\n",
            "Token: this, Predicted Label: O\n",
            "Token: must, Predicted Label: O\n",
            "Token: be, Predicted Label: O\n",
            "Token: an, Predicted Label: O\n",
            "Token: ancient, Predicted Label: O\n",
            "Token: print, Predicted Label: O\n",
            "Token: date,, Predicted Label: O\n",
            "Token: right?, Predicted Label: O\n",
            "Token: But, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: fact,, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: print, Predicted Label: O\n",
            "Token: date, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: early, Predicted Label: O\n",
            "Token: 1980s, Predicted Label: O\n",
            "Token: when, Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: would, Predicted Label: O\n",
            "Token: have, Predicted Label: O\n",
            "Token: been, Predicted Label: O\n",
            "Token: starting, Predicted Label: O\n",
            "Token: primary, Predicted Label: O\n",
            "Token: school, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: forming, Predicted Label: O\n",
            "Token: an, Predicted Label: O\n",
            "Token: understanding, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: myself, Predicted Label: O\n",
            "Token: outside, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: family, Predicted Label: O\n",
            "Token: unit, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: as, Predicted Label: O\n",
            "Token: related, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: other, Predicted Label: O\n",
            "Token: kids, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: world, Predicted Label: O\n",
            "Token: around, Predicted Label: O\n",
            "Token: me,, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: needless, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: say,, Predicted Label: O\n",
            "Token: thank, Predicted Label: O\n",
            "Token: God, Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: wasn't, Predicted Label: O\n",
            "Token: using, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: Tsara's, Predicted Label: O\n",
            "Token: back, Predicted Label: O\n",
            "Token: then., Predicted Label: O\n",
            "Token: back, Predicted Label: O\n",
            "Token: then., Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: mean,, Predicted Label: O\n",
            "Token: from, Predicted Label: O\n",
            "Token: this, Predicted Label: O\n",
            "Token: entry,, Predicted Label: O\n",
            "Token: it, Predicted Label: O\n",
            "Token: would, Predicted Label: O\n",
            "Token: seem, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: born, Predicted Label: O\n",
            "Token: into, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: world, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: perceived, Predicted Label: O\n",
            "Token: someone, Predicted Label: O\n",
            "Token: like, Predicted Label: O\n",
            "Token: me, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: have, Predicted Label: O\n",
            "Token: nothing, Predicted Label: O\n",
            "Token: positive, Predicted Label: O\n",
            "Token: whatsoever, Predicted Label: O\n",
            "Token: going, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: them., Predicted Label: O\n",
            "Token: When,, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: fact,, Predicted Label: O\n",
            "Token: today,, Predicted Label: O\n",
            "Token: I'm, Predicted Label: O\n",
            "Token: celebrated, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: opportunities, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: adventures, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: life, Predicted Label: O\n",
            "Token: have, Predicted Label: O\n",
            "Token: procured., Predicted Label: O\n",
            "Token: So, Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: immediately, Predicted Label: O\n",
            "Token: went, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: look, Predicted Label: O\n",
            "Token: up, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: 2009, Predicted Label: O\n",
            "Token: online, Predicted Label: O\n",
            "Token: edition,, Predicted Label: O\n",
            "Token: expecting, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: find, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: revision, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: expecting, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: find, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: revision, Predicted Label: O\n",
            "Token: worth, Predicted Label: O\n",
            "Token: noting,, Predicted Label: O\n",
            "Token: here's, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: updated, Predicted Label: O\n",
            "Token: version, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: this, Predicted Label: O\n",
            "Token: entry., Predicted Label: O\n",
            "Token: Unfortunately,, Predicted Label: O\n",
            "Token: it's, Predicted Label: O\n",
            "Token: not, Predicted Label: O\n",
            "Token: much, Predicted Label: O\n",
            "Token: better., Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: find, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: last, Predicted Label: O\n",
            "Token: two, Predicted Label: O\n",
            "Token: words, Predicted Label: O\n",
            "Token: under, Predicted Label: O\n",
            "Token: near-antonyms,, Predicted Label: O\n",
            "Token: particularly, Predicted Label: O\n",
            "Token: unsettling,, Predicted Label: O\n",
            "Token: whole,, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: wholesome., Predicted Label: O\n",
            "Token: So,, Predicted Label: O\n",
            "Token: It's, Predicted Label: O\n",
            "Token: not, Predicted Label: O\n",
            "Token: just, Predicted Label: O\n",
            "Token: about, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: words., Predicted Label: O\n",
            "Token: It's, Predicted Label: O\n",
            "Token: what, Predicted Label: O\n",
            "Token: we, Predicted Label: O\n",
            "Token: believe, Predicted Label: O\n",
            "Token: about, Predicted Label: O\n",
            "Token: people, Predicted Label: O\n",
            "Token: when, Predicted Label: O\n",
            "Token: we, Predicted Label: O\n",
            "Token: name, Predicted Label: O\n",
            "Token: them, Predicted Label: O\n",
            "Token: with, Predicted Label: O\n",
            "Token: these, Predicted Label: O\n",
            "Token: words,, Predicted Label: O\n",
            "Token: about, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: values, Predicted Label: O\n",
            "Token: behind, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: words, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: how, Predicted Label: O\n",
            "Token: we, Predicted Label: O\n",
            "Token: construct, Predicted Label: O\n",
            "Token: those, Predicted Label: O\n",
            "Token: values., Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: struck, Predicted Label: O\n",
            "Token: those, Predicted Label: O\n",
            "Token: values,, Predicted Label: O\n",
            "Token: our, Predicted Label: O\n",
            "Token: language, Predicted Label: O\n",
            "Token: affects, Predicted Label: O\n",
            "Token: our, Predicted Label: O\n",
            "Token: thinking, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: how, Predicted Label: O\n",
            "Token: we, Predicted Label: O\n",
            "Token: view, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: world, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: how, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: view, Predicted Label: O\n",
            "Token: other, Predicted Label: O\n",
            "Token: people., Predicted Label: O\n",
            "Token: In, Predicted Label: O\n",
            "Token: fact,, Predicted Label: O\n",
            "Token: many, Predicted Label: O\n",
            "Token: ancient, Predicted Label: O\n",
            "Token: societies,, Predicted Label: O\n",
            "Token: including, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: Greeks, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: Romans,, Predicted Label: O\n",
            "Token: believed, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: utter, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: curse, Predicted Label: O\n",
            "Token: verbally, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: so, Predicted Label: O\n",
            "Token: powerful, Predicted Label: O\n",
            "Token: because, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: say, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: thing, Predicted Label: O\n",
            "Token: out, Predicted Label: O\n",
            "Token: loud, Predicted Label: O\n",
            "Token: brought, Predicted Label: O\n",
            "Token: it, Predicted Label: O\n",
            "Token: into, Predicted Label: O\n",
            "Token: existence., Predicted Label: O\n",
            "Token: So, Predicted Label: O\n",
            "Token: what, Predicted Label: O\n",
            "Token: reality, Predicted Label: O\n",
            "Token: do, Predicted Label: O\n",
            "Token: we, Predicted Label: O\n",
            "Token: want, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: call, Predicted Label: O\n",
            "Token: into, Predicted Label: O\n",
            "Token: existence?, Predicted Label: O\n",
            "Token: A, Predicted Label: O\n",
            "Token: person, Predicted Label: O\n",
            "Token: who, Predicted Label: O\n",
            "Token: is, Predicted Label: O\n",
            "Token: limited, Predicted Label: O\n",
            "Token: or, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: person, Predicted Label: O\n",
            "Token: or, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: person, Predicted Label: O\n",
            "Token: who's, Predicted Label: O\n",
            "Token: empowered., Predicted Label: O\n",
            "Token: By, Predicted Label: O\n",
            "Token: casually, Predicted Label: O\n",
            "Token: doing, Predicted Label: O\n",
            "Token: something, Predicted Label: O\n",
            "Token: as, Predicted Label: O\n",
            "Token: simple, Predicted Label: O\n",
            "Token: as, Predicted Label: O\n",
            "Token: naming, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: person, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: child,, Predicted Label: O\n",
            "Token: we, Predicted Label: O\n",
            "Token: might, Predicted Label: O\n",
            "Token: be, Predicted Label: O\n",
            "Token: putting, Predicted Label: O\n",
            "Token: lids, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: casting, Predicted Label: O\n",
            "Token: shadows, Predicted Label: O\n",
            "Token: on, Predicted Label: O\n",
            "Token: their, Predicted Label: O\n",
            "Token: power., Predicted Label: O\n",
            "Token: Wouldn't, Predicted Label: O\n",
            "Token: we, Predicted Label: O\n",
            "Token: want, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: open, Predicted Label: O\n",
            "Token: doors, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: them, Predicted Label: O\n",
            "Token: instead?, Predicted Label: O\n",
            "Token: Once, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: person, Predicted Label: O\n",
            "Token: who, Predicted Label: O\n",
            "Token: opened, Predicted Label: O\n",
            "Token: doors, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: me, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: childhood, Predicted Label: O\n",
            "Token: doctor, Predicted Label: O\n",
            "Token: at, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: A.I., Predicted Label: O\n",
            "Token: DuPont, Predicted Label: O\n",
            "Token: Institute, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: Wilmington,, Predicted Label: O\n",
            "Token: Delaware., Predicted Label: O\n",
            "Token: His, Predicted Label: O\n",
            "Token: name, Predicted Label: O\n",
            "Token: is, Predicted Label: O\n",
            "Token: Dr., Predicted Label: O\n",
            "Token: where?, Predicted Label: O\n",
            "Token: His, Predicted Label: O\n",
            "Token: name, Predicted Label: O\n",
            "Token: is, Predicted Label: O\n",
            "Token: Dr., Predicted Label: O\n",
            "Token: Pete, Predicted Label: O\n",
            "Token: Zotillo., Predicted Label: O\n",
            "Token: I'm, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: Italian, Predicted Label: O\n",
            "Token: American, Predicted Label: O\n",
            "Token: whose, Predicted Label: O\n",
            "Token: name, Predicted Label: O\n",
            "Token: apparently, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: too, Predicted Label: O\n",
            "Token: difficult, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: most, Predicted Label: O\n",
            "Token: Americans, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: pronounce,, Predicted Label: O\n",
            "Token: so, Predicted Label: O\n",
            "Token: he, Predicted Label: O\n",
            "Token: went, Predicted Label: O\n",
            "Token: by, Predicted Label: O\n",
            "Token: Dr., Predicted Label: O\n",
            "Token: P., Predicted Label: O\n",
            "Token: And, Predicted Label: O\n",
            "Token: Dr.P, Predicted Label: O\n",
            "Token: always, Predicted Label: O\n",
            "Token: wore, Predicted Label: O\n",
            "Token: really, Predicted Label: O\n",
            "Token: colorful, Predicted Label: O\n",
            "Token: bow, Predicted Label: O\n",
            "Token: ties, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: had, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: very, Predicted Label: O\n",
            "Token: perfect, Predicted Label: O\n",
            "Token: disposition, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: work, Predicted Label: O\n",
            "Token: with, Predicted Label: O\n",
            "Token: children., Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: loved, Predicted Label: O\n",
            "Token: almost, Predicted Label: O\n",
            "Token: everything, Predicted Label: O\n",
            "Token: about, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: time, Predicted Label: O\n",
            "Token: spent, Predicted Label: O\n",
            "Token: at, Predicted Label: O\n",
            "Token: this, Predicted Label: O\n",
            "Token: hospital,, Predicted Label: O\n",
            "Token: which, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: exception, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: physical, Predicted Label: O\n",
            "Token: therapy, Predicted Label: O\n",
            "Token: sessions., Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: had, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: do, Predicted Label: O\n",
            "Token: sessions., Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: had, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: do, Predicted Label: O\n",
            "Token: what, Predicted Label: O\n",
            "Token: seemed, Predicted Label: O\n",
            "Token: like, Predicted Label: O\n",
            "Token: innumerable, Predicted Label: O\n",
            "Token: repetitions, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: exercises, Predicted Label: O\n",
            "Token: with, Predicted Label: O\n",
            "Token: these, Predicted Label: O\n",
            "Token: thick,, Predicted Label: O\n",
            "Token: elastic, Predicted Label: O\n",
            "Token: bands,, Predicted Label: O\n",
            "Token: different, Predicted Label: O\n",
            "Token: colors,, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: know,, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: help, Predicted Label: O\n",
            "Token: build, Predicted Label: O\n",
            "Token: up, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: leg, Predicted Label: O\n",
            "Token: muscles., Predicted Label: O\n",
            "Token: And, Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: hated, Predicted Label: O\n",
            "Token: these, Predicted Label: O\n",
            "Token: bands, Predicted Label: O\n",
            "Token: more, Predicted Label: O\n",
            "Token: than, Predicted Label: O\n",
            "Token: anything., Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: hated, Predicted Label: O\n",
            "Token: them,, Predicted Label: O\n",
            "Token: had, Predicted Label: O\n",
            "Token: names, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: them,, Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: hate, Predicted Label: O\n",
            "Token: them., Predicted Label: O\n",
            "Token: And, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: know, Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: already, Predicted Label: O\n",
            "Token: bargaining, Predicted Label: O\n",
            "Token: as, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: five-year-old, Predicted Label: O\n",
            "Token: child, Predicted Label: O\n",
            "Token: with, Predicted Label: O\n",
            "Token: Dr., Predicted Label: O\n",
            "Token: P, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: try, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: get, Predicted Label: O\n",
            "Token: out, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: doing, Predicted Label: O\n",
            "Token: these, Predicted Label: O\n",
            "Token: exercises, Predicted Label: O\n",
            "Token: unsuccessfully,, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: course., Predicted Label: O\n",
            "Token: And, Predicted Label: O\n",
            "Token: one, Predicted Label: O\n",
            "Token: day, Predicted Label: O\n",
            "Token: he, Predicted Label: O\n",
            "Token: came, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: he, Predicted Label: O\n",
            "Token: came, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: session,, Predicted Label: O\n",
            "Token: exhaustive, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: unforgiving, Predicted Label: O\n",
            "Token: these, Predicted Label: O\n",
            "Token: sessions., Predicted Label: O\n",
            "Token: And, Predicted Label: O\n",
            "Token: he, Predicted Label: O\n",
            "Token: said, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: me,, Predicted Label: O\n",
            "Token: wow,, Predicted Label: O\n",
            "Token: Amy,, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: are, Predicted Label: O\n",
            "Token: such, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: strong,, Predicted Label: O\n",
            "Token: powerful, Predicted Label: O\n",
            "Token: little, Predicted Label: O\n",
            "Token: girl., Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: think, Predicted Label: O\n",
            "Token: you're, Predicted Label: O\n",
            "Token: going, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: break, Predicted Label: O\n",
            "Token: one, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: those, Predicted Label: O\n",
            "Token: bands., Predicted Label: O\n",
            "Token: When, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: do, Predicted Label: O\n",
            "Token: break, Predicted Label: O\n",
            "Token: it,, Predicted Label: O\n",
            "Token: I'm, Predicted Label: O\n",
            "Token: going, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: give, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: 100, Predicted Label: O\n",
            "Token: bucks., Predicted Label: O\n",
            "Token: Now,, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: course,, Predicted Label: O\n",
            "Token: this, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: simple, Predicted Label: O\n",
            "Token: ploy, Predicted Label: O\n",
            "Token: on, Predicted Label: O\n",
            "Token: Dr., Predicted Label: O\n",
            "Token: P's, Predicted Label: O\n",
            "Token: part, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: get, Predicted Label: O\n",
            "Token: me, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: do, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: exercises, Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: didn't, Predicted Label: O\n",
            "Token: want, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: do, Predicted Label: O\n",
            "Token: before, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: prospect, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: being, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: richest, Predicted Label: O\n",
            "Token: five-year-old, Predicted Label: O\n",
            "Token: before, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: prospect, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: being, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: richest, Predicted Label: O\n",
            "Token: fighter, Predicted Label: O\n",
            "Token: old, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: second, Predicted Label: O\n",
            "Token: floor, Predicted Label: O\n",
            "Token: award., Predicted Label: O\n",
            "Token: But, Predicted Label: O\n",
            "Token: what, Predicted Label: O\n",
            "Token: he, Predicted Label: O\n",
            "Token: effectively, Predicted Label: O\n",
            "Token: did, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: me, Predicted Label: O\n",
            "Token: was, Predicted Label: O\n",
            "Token: reshape, Predicted Label: O\n",
            "Token: an, Predicted Label: O\n",
            "Token: awful, Predicted Label: O\n",
            "Token: daily, Predicted Label: O\n",
            "Token: occurrence, Predicted Label: O\n",
            "Token: into, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: new, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: promising, Predicted Label: O\n",
            "Token: experience, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: me., Predicted Label: O\n",
            "Token: And, Predicted Label: O\n",
            "Token: I, Predicted Label: O\n",
            "Token: have, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: wonder, Predicted Label: O\n",
            "Token: today, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: what, Predicted Label: O\n",
            "Token: extent, Predicted Label: O\n",
            "Token: his, Predicted Label: O\n",
            "Token: vision, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: his, Predicted Label: O\n",
            "Token: declaration, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: me, Predicted Label: O\n",
            "Token: as, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: strong, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: powerful, Predicted Label: O\n",
            "Token: little, Predicted Label: O\n",
            "Token: girl, Predicted Label: O\n",
            "Token: shaped, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: own, Predicted Label: O\n",
            "Token: view, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: myself, Predicted Label: O\n",
            "Token: as, Predicted Label: O\n",
            "Token: an, Predicted Label: O\n",
            "Token: inherently, Predicted Label: O\n",
            "Token: strong, Predicted Label: O\n",
            "Token: as, Predicted Label: O\n",
            "Token: an, Predicted Label: O\n",
            "Token: inherently, Predicted Label: O\n",
            "Token: strong,, Predicted Label: O\n",
            "Token: powerful,, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: athletic, Predicted Label: O\n",
            "Token: person, Predicted Label: O\n",
            "Token: well, Predicted Label: O\n",
            "Token: into, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: future., Predicted Label: O\n",
            "Token: This, Predicted Label: O\n",
            "Token: is, Predicted Label: O\n",
            "Token: an, Predicted Label: O\n",
            "Token: example, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: how, Predicted Label: O\n",
            "Token: adults, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: positions, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: power, Predicted Label: O\n",
            "Token: can, Predicted Label: O\n",
            "Token: ignite, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: power, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: child., Predicted Label: O\n",
            "Token: But, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: previous, Predicted Label: O\n",
            "Token: instances, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: those, Predicted Label: O\n",
            "Token: Bessara, Predicted Label: O\n",
            "Token: centuries,, Predicted Label: O\n",
            "Token: our, Predicted Label: O\n",
            "Token: language, Predicted Label: O\n",
            "Token: isn't, Predicted Label: O\n",
            "Token: allowing, Predicted Label: O\n",
            "Token: us, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: evolve, Predicted Label: O\n",
            "Token: into, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: reality, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: we, Predicted Label: O\n",
            "Token: would, Predicted Label: O\n",
            "Token: all, Predicted Label: O\n",
            "Token: want., Predicted Label: O\n",
            "Token: The, Predicted Label: O\n",
            "Token: possibility, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: an, Predicted Label: O\n",
            "Token: individual, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: see, Predicted Label: O\n",
            "Token: themselves, Predicted Label: O\n",
            "Token: as, Predicted Label: O\n",
            "Token: capable., Predicted Label: O\n",
            "Token: is, Predicted Label: O\n",
            "Token: capable., Predicted Label: O\n",
            "Token: Our, Predicted Label: O\n",
            "Token: language, Predicted Label: O\n",
            "Token: hasn't, Predicted Label: O\n",
            "Token: caught, Predicted Label: O\n",
            "Token: up, Predicted Label: O\n",
            "Token: with, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: changes, Predicted Label: O\n",
            "Token: in, Predicted Label: O\n",
            "Token: our, Predicted Label: O\n",
            "Token: society,, Predicted Label: O\n",
            "Token: many, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: which, Predicted Label: O\n",
            "Token: have, Predicted Label: O\n",
            "Token: been, Predicted Label: O\n",
            "Token: brought, Predicted Label: O\n",
            "Token: about, Predicted Label: O\n",
            "Token: by, Predicted Label: O\n",
            "Token: technology., Predicted Label: O\n",
            "Token: Certainly, Predicted Label: O\n",
            "Token: from, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: medical, Predicted Label: O\n",
            "Token: standpoint,, Predicted Label: O\n",
            "Token: my, Predicted Label: O\n",
            "Token: legs,, Predicted Label: O\n",
            "Token: you, Predicted Label: O\n",
            "Token: know,, Predicted Label: O\n",
            "Token: laser, Predicted Label: O\n",
            "Token: surgery, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: vision, Predicted Label: O\n",
            "Token: impairment,, Predicted Label: O\n",
            "Token: titanium, Predicted Label: O\n",
            "Token: knees, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: hip, Predicted Label: O\n",
            "Token: replacements, Predicted Label: O\n",
            "Token: for, Predicted Label: O\n",
            "Token: aging, Predicted Label: O\n",
            "Token: bodies, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: are, Predicted Label: O\n",
            "Token: allowing, Predicted Label: O\n",
            "Token: people, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: more, Predicted Label: O\n",
            "Token: fully, Predicted Label: O\n",
            "Token: engage, Predicted Label: O\n",
            "Token: with, Predicted Label: O\n",
            "Token: their, Predicted Label: O\n",
            "Token: abilities, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: move, Predicted Label: O\n",
            "Token: beyond, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: limits, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: nature, Predicted Label: O\n",
            "Token: has, Predicted Label: O\n",
            "Token: imposed, Predicted Label: O\n",
            "Token: on, Predicted Label: O\n",
            "Token: them., Predicted Label: O\n",
            "Token: Not, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: mention, Predicted Label: O\n",
            "Token: Not, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: mention, Predicted Label: O\n",
            "Token: social, Predicted Label: O\n",
            "Token: networking, Predicted Label: O\n",
            "Token: platforms., Predicted Label: O\n",
            "Token: It, Predicted Label: O\n",
            "Token: allows, Predicted Label: O\n",
            "Token: people, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: self-identify,, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: claim, Predicted Label: O\n",
            "Token: their, Predicted Label: O\n",
            "Token: own, Predicted Label: O\n",
            "Token: descriptions, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: themselves, Predicted Label: O\n",
            "Token: so, Predicted Label: O\n",
            "Token: they, Predicted Label: O\n",
            "Token: can, Predicted Label: O\n",
            "Token: go, Predicted Label: O\n",
            "Token: align, Predicted Label: O\n",
            "Token: with, Predicted Label: O\n",
            "Token: global, Predicted Label: O\n",
            "Token: groups, Predicted Label: O\n",
            "Token: of, Predicted Label: O\n",
            "Token: their, Predicted Label: O\n",
            "Token: own, Predicted Label: O\n",
            "Token: choosing., Predicted Label: O\n",
            "Token: So, Predicted Label: O\n",
            "Token: perhaps, Predicted Label: O\n",
            "Token: technology, Predicted Label: O\n",
            "Token: is, Predicted Label: O\n",
            "Token: revealing, Predicted Label: O\n",
            "Token: more, Predicted Label: O\n",
            "Token: clearly, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: us, Predicted Label: O\n",
            "Token: now, Predicted Label: O\n",
            "Token: what, Predicted Label: O\n",
            "Token: has, Predicted Label: O\n",
            "Token: always, Predicted Label: O\n",
            "Token: been, Predicted Label: O\n",
            "Token: a, Predicted Label: O\n",
            "Token: truth., Predicted Label: O\n",
            "Token: That, Predicted Label: O\n",
            "Token: everyone, Predicted Label: O\n",
            "Token: has, Predicted Label: O\n",
            "Token: something, Predicted Label: O\n",
            "Token: rare, Predicted Label: O\n",
            "Token: and, Predicted Label: O\n",
            "Token: powerful, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: offer, Predicted Label: O\n",
            "Token: our, Predicted Label: O\n",
            "Token: society., Predicted Label: O\n",
            "Token: And, Predicted Label: O\n",
            "Token: that, Predicted Label: O\n",
            "Token: the, Predicted Label: O\n",
            "Token: human, Predicted Label: O\n",
            "Token: ability, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: adapt, Predicted Label: O\n",
            "Token: is, Predicted Label: O\n",
            "Token: our, Predicted Label: O\n",
            "Token: greatest, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: adapt, Predicted Label: O\n",
            "Token: is, Predicted Label: O\n",
            "Token: our, Predicted Label: O\n",
            "Token: greatest, Predicted Label: O\n",
            "Token: asset., Predicted Label: O\n",
            "Token: A, Predicted Label: O\n",
            "Token: human, Predicted Label: O\n",
            "Token: ability, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n",
            "Token: adapt,, Predicted Label: O\n",
            "Token: it's, Predicted Label: O\n",
            "Token: an, Predicted Label: O\n",
            "Token: interesting, Predicted Label: O\n",
            "Token: thing, Predicted Label: O\n",
            "Token: because, Predicted Label: O\n",
            "Token: people, Predicted Label: O\n",
            "Token: have, Predicted Label: O\n",
            "Token: continually, Predicted Label: O\n",
            "Token: wanted, Predicted Label: O\n",
            "Token: to, Predicted Label: O\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}